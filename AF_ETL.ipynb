{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set File Dir for Weekly Data\n",
    "file_dir = 'C:\\\\MSCA\\\\2020.04 31009 Machine Learning and Predictive Analytics\\\\Final Project\\\\test\\\\'\n",
    "\n",
    "# Column Info\n",
    "p_info = ['x', 'y', 's', 'a', 'dis', 'o', 'dir']\n",
    "routes = ['ANGLE', 'CORNER', 'CROSS', 'FLAT', 'GO','HITCH', 'IN', 'OUT','POST', 'SCREEN', 'SLANT', 'WHEEL']\n",
    "p_list = p_info+routes\n",
    "\n",
    "# Import Player Data\n",
    "players = pd.read_csv('players.csv')\n",
    "players = players.append({'nflId':0,\n",
    "                          'height':0,\n",
    "                          'weight':0,\n",
    "                          'birthDate': '2018-01-01',\n",
    "                          'collegeName':'None',\n",
    "                          'position':'BALL', 'displayName':'BALL'}, ignore_index=True)\n",
    "players['nflId'] = players['nflId'].astype(np.int64)\n",
    "\n",
    "# Import Plays data\n",
    "plays = pd.read_csv('plays.csv')\n",
    "\n",
    "# Create Function for Filling in Data\n",
    "def nfl_norm(c):\n",
    "    for i in pf.index:\n",
    "        e_id = pf['e_id'][i]\n",
    "        c_x = c+'_'+str(pf['nflId'][i])\n",
    "        v_x =  pf[c][i]\n",
    "        n_i = pf_norm.index[pf_norm['e_id'] == e_id]\n",
    "        pf_norm.at[n_i, c_x] = v_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(file_dir):\n",
    "    path = file_dir+filename\n",
    "    pf = pd.read_csv(path)\n",
    "    \n",
    "    # Create e_id field and gp_id\n",
    "    pf['e_id'] = pf['gameId'].map(str)+pf['playId'].map(str)+pf['frameId'].map(str)\n",
    "    pf['e_id'] = pf['e_id'].astype(np.int64)\n",
    "    \n",
    "    pf['gp_id'] = pf['gameId'].map(str)+pf['playId'].map(str)\n",
    "    pf['gp_id'] = pf['gp_id'].astype(np.int64)\n",
    "    \n",
    "    # Change nflId to int\n",
    "    pf = pf.fillna(0)\n",
    "    pf['nflId'] = pf['nflId'].astype(np.int64)\n",
    "    \n",
    "    # Create Play Result Field\n",
    "    passing_df = pf[pf['event'].isin(['pass_outcome_touchdown',\n",
    "                                      'pass_outcome_caught',\n",
    "                                      'pass_outcome_incomplete',\n",
    "                                      'pass_outcome_interception'])]\n",
    "    \n",
    "    passing_df = passing_df[['gp_id', 'event']]\n",
    "    passing_df.columns = ['gp_id', 'result']  \n",
    "    passing_df = passing_df.drop_duplicates()\n",
    "    pf = pd.merge(pf, passing_df['result'], left_on=pf['gp_id'], right_on=passing_df['gp_id'], how='left')\n",
    "    \n",
    "    ########  ADD FEATURES HERE  ########\n",
    "    \n",
    "    # Isolate Pass Forward\n",
    "    pf = pf[pf['event'] == 'pass_forward']\n",
    "    \n",
    "    # Create Base Dummy Fields for Route\n",
    "    pf['route'] = pf['route'].replace(['undefined'], 0)\n",
    "    r = pd.get_dummies(pf['route'], columns=routes, drop_first=True, dtype=int)\n",
    "    pf = pd.concat([pf,r], axis = 1)\n",
    "    \n",
    "    # Crate Normalized Template\n",
    "    pf_norm = pf[['e_id', 'gp_id', 'result']]\n",
    "    pf_norm = pf_norm.drop_duplicates()\n",
    "    pf_norm = pf_norm.reset_index(drop=True)\n",
    "    \n",
    "    for i in players['nflId']:\n",
    "        i =str(i)\n",
    "        for j in p_list:\n",
    "            pf_norm[j+'_'+i] = 0\n",
    "            \n",
    "    pf_norm = pf_norm.fillna(0)\n",
    "    \n",
    "    for p in p_list:\n",
    "        nfl_norm(p)\n",
    "    \n",
    "    # Export to CSV\n",
    "    nf = 'norm_'+filename\n",
    "    pf_norm.to_csv(nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976.1059892177582\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e_id', 'gp_id', 'result', 'x_2539334', 'y_2539334']\n"
     ]
    }
   ],
   "source": [
    "p_col = list(pf_norm.columns.values)\n",
    "print(p_col[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
